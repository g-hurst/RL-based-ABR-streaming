{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea01379e-834e-454d-880f-ad9cb95e1754",
   "metadata": {},
   "source": [
    "# Creating an RL Based ABR Streaming Algorithm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2521427b-e5ec-41c5-b571-90d9eda20348",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import argparse\n",
    "import random\n",
    "import math\n",
    "import io\n",
    "import contextlib\n",
    "\n",
    "import sabre\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66853135-291c-4b49-8b14-69ba6b8a39f0",
   "metadata": {},
   "source": [
    "## Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27df2093-b1db-4a7f-849f-f6fe4e2785c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary of Network Data:\n",
      "  hd_traces: \n",
      "    Training 750 samples, 149250 steps to train\n",
      "    Testing  250 samples, 49750  steps to test\n",
      "\n",
      "  sd_traces: \n",
      "    Training 750 samples, 149250 steps to train\n",
      "    Testing  250 samples, 49750  steps to test\n",
      "\n",
      "  3G_traces: \n",
      "    Training 64 samples, 12736 steps to train\n",
      "    Testing  22 samples, 4378  steps to test\n",
      "\n",
      "  4G_traces: \n",
      "    Training 30 samples, 5970 steps to train\n",
      "    Testing  10 samples, 1990  steps to test\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_files(d): \n",
    "    return [os.path.join(d, f) for f in os.listdir(d)]\n",
    "    \n",
    "def get_movie_manifest(movie_filename):\n",
    "    manifest = sabre.load_json(movie_filename)                                                                                                                                                        \n",
    "    manifest = sabre.ManifestInfo(segment_time = manifest['segment_duration_ms'], \n",
    "                    bitrates    = manifest['bitrates_kbps'],                                         \n",
    "                    utilities    = [math.log(b) - math.log(manifest['bitrates_kbps'][0]) for b in manifest['bitrates_kbps']], \n",
    "                    segments     = manifest['segment_sizes_bits'])\n",
    "    return manifest\n",
    "    \n",
    "network_hd_dir = '../data/hd_fs'\n",
    "network_sd_dir = '../data/sd_fs'\n",
    "network_3G_dir = '../data/3Glogs'\n",
    "network_4G_dir = '../data/4Glogs'\n",
    "\n",
    "network_traces = {\n",
    "    'hd_traces':get_files(network_hd_dir),\n",
    "    'sd_traces':get_files(network_sd_dir),\n",
    "    '3G_traces':get_files(network_3G_dir),\n",
    "    '4G_traces':get_files(network_4G_dir),\n",
    "}\n",
    "\n",
    "movies = ['../data/bbb.json',] #  '../data/bbb4k.json']\n",
    "\n",
    "# for now seed the random in order to save the trained model one day\n",
    "# and then re-run the code to test another day\n",
    "random.seed(69420) \n",
    "\n",
    "n_views_per_trace = 1\n",
    "n_chunks = sum(len(get_movie_manifest(m).segments) for m in movies)\n",
    "print('Summary of Network Data:')\n",
    "test_train_split = 0.75\n",
    "for k, v in network_traces.items():\n",
    "    np.random.shuffle(v)\n",
    "    idx = int(np.floor(test_train_split * len(v)))\n",
    "    n_train = n_views_per_trace * n_chunks * idx\n",
    "    n_test  = n_chunks * (len(v) - idx)\n",
    "    network_traces[k] = {\n",
    "        'train': v[:idx],\n",
    "        'train_steps': n_train,\n",
    "        'test':  v[idx:],\n",
    "        'test_steps': n_test\n",
    "    }\n",
    "    print(f'  {k}: ')\n",
    "    print(f'    Training {idx} samples, {n_train} steps to train')\n",
    "    print(f'    Testing  {len(v) - idx} samples, {n_test}  steps to test')\n",
    "    print('')\n",
    "\n",
    "DATA = network_traces['hd_traces']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a53af16-6872-4747-99e1-bafc07da1a20",
   "metadata": {},
   "source": [
    "## Train and save several models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28e03ff9-acb6-451a-a4cd-748cb0c16e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from environment import ABR_Env\n",
    "\n",
    "qoe_alpha, qoe_beta, qoe_delta = (1, 1, 1)\n",
    "\n",
    "env = ABR_Env(\n",
    "    DATA['train'],\n",
    "    movies,\n",
    "    r_multipliers=[qoe_alpha, qoe_beta, qoe_delta],\n",
    ")\n",
    "env_train = env.get_sb_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9baa29d0-0131-471f-a0e6-c369dce0df2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'sabre' has no attribute 't'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mstable_baselines3\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m A2C\n\u001b[1;32m      3\u001b[0m model_a2c \u001b[38;5;241m=\u001b[39m A2C(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMultiInputPolicy\u001b[39m\u001b[38;5;124m'\u001b[39m, env_train, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m \u001b[43mmodel_a2c\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDATA\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain_steps\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m model_a2c\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../models/a2c.model\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/school/ECE595-RL/RL-based-ABR-streaming/.env/lib/python3.10/site-packages/stable_baselines3/a2c/a2c.py:201\u001b[0m, in \u001b[0;36mA2C.learn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlearn\u001b[39m(\n\u001b[1;32m    193\u001b[0m     \u001b[38;5;28mself\u001b[39m: SelfA2C,\n\u001b[1;32m    194\u001b[0m     total_timesteps: \u001b[38;5;28mint\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    199\u001b[0m     progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    200\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SelfA2C:\n\u001b[0;32m--> 201\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    203\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    205\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtb_log_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    206\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    207\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    208\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/school/ECE595-RL/RL-based-ABR-streaming/.env/lib/python3.10/site-packages/stable_baselines3/common/on_policy_algorithm.py:323\u001b[0m, in \u001b[0;36mOnPolicyAlgorithm.learn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    320\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    322\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_timesteps \u001b[38;5;241m<\u001b[39m total_timesteps:\n\u001b[0;32m--> 323\u001b[0m     continue_training \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect_rollouts\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrollout_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_rollout_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_steps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    325\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m continue_training:\n\u001b[1;32m    326\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/school/ECE595-RL/RL-based-ABR-streaming/.env/lib/python3.10/site-packages/stable_baselines3/common/on_policy_algorithm.py:218\u001b[0m, in \u001b[0;36mOnPolicyAlgorithm.collect_rollouts\u001b[0;34m(self, env, callback, rollout_buffer, n_rollout_steps)\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    214\u001b[0m         \u001b[38;5;66;03m# Otherwise, clip the actions to avoid out of bound error\u001b[39;00m\n\u001b[1;32m    215\u001b[0m         \u001b[38;5;66;03m# as we are sampling from an unbounded Gaussian distribution\u001b[39;00m\n\u001b[1;32m    216\u001b[0m         clipped_actions \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mclip(actions, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_space\u001b[38;5;241m.\u001b[39mlow, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_space\u001b[38;5;241m.\u001b[39mhigh)\n\u001b[0;32m--> 218\u001b[0m new_obs, rewards, dones, infos \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclipped_actions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_timesteps \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mnum_envs\n\u001b[1;32m    222\u001b[0m \u001b[38;5;66;03m# Give access to local variables\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/school/ECE595-RL/RL-based-ABR-streaming/.env/lib/python3.10/site-packages/stable_baselines3/common/vec_env/base_vec_env.py:206\u001b[0m, in \u001b[0;36mVecEnv.step\u001b[0;34m(self, actions)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;124;03mStep the environments with the given action\u001b[39;00m\n\u001b[1;32m    201\u001b[0m \n\u001b[1;32m    202\u001b[0m \u001b[38;5;124;03m:param actions: the action\u001b[39;00m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;124;03m:return: observation, reward, done, information\u001b[39;00m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_async(actions)\n\u001b[0;32m--> 206\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/school/ECE595-RL/RL-based-ABR-streaming/.env/lib/python3.10/site-packages/stable_baselines3/common/vec_env/dummy_vec_env.py:58\u001b[0m, in \u001b[0;36mDummyVecEnv.step_wait\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep_wait\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m VecEnvStepReturn:\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;66;03m# Avoid circular imports\u001b[39;00m\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m env_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_envs):\n\u001b[0;32m---> 58\u001b[0m         obs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_rews[env_idx], terminated, truncated, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_infos[env_idx] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menvs\u001b[49m\u001b[43m[\u001b[49m\u001b[43menv_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactions\u001b[49m\u001b[43m[\u001b[49m\u001b[43menv_idx\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m         \u001b[38;5;66;03m# convert to SB3 VecEnv api\u001b[39;00m\n\u001b[1;32m     62\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_dones[env_idx] \u001b[38;5;241m=\u001b[39m terminated \u001b[38;5;129;01mor\u001b[39;00m truncated\n",
      "File \u001b[0;32m~/Documents/school/ECE595-RL/RL-based-ABR-streaming/src/environment.py:41\u001b[0m, in \u001b[0;36mABR_Env.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     37\u001b[0m info \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_testing:\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;66;03m# get latency, throutput, and rebuff_time from sabre globals\u001b[39;00m\n\u001b[0;32m---> 41\u001b[0m     throughput \u001b[38;5;241m=\u001b[39m \u001b[43msabre\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mt\u001b[49m\n\u001b[1;32m     42\u001b[0m     latency    \u001b[38;5;241m=\u001b[39m sabre\u001b[38;5;241m.\u001b[39ml\n\u001b[1;32m     43\u001b[0m     rebuff_time \u001b[38;5;241m=\u001b[39m sabre\u001b[38;5;241m.\u001b[39mrebuff_time \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39memulator\u001b[38;5;241m.\u001b[39mlast_rebuff_time\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'sabre' has no attribute 't'"
     ]
    }
   ],
   "source": [
    "from stable_baselines3 import A2C\n",
    "\n",
    "model_a2c = A2C('MultiInputPolicy', env_train, verbose=1, device='cpu')\n",
    "model_a2c.learn(total_timesteps=DATA['train_steps'])\n",
    "model_a2c.save('../models/a2c.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de9a7f3f-1c88-4996-8276-40b4dacf68a0",
   "metadata": {},
   "source": [
    "## Test the ABR Algorithms and Gather Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8aab492-9a3a-4028-8c02-e57c8dc0dbfe",
   "metadata": {},
   "source": [
    "The argparse arguments were copied and pased from the modified `sabre.py` file. Note, minor changes were made where any variable that was used had to be changed to sabre.var_name. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733c4fff-ba58-4803-87b8-06322ac22a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description = 'Simulate an ABR session.',\n",
    "                                 formatter_class = argparse.ArgumentDefaultsHelpFormatter)\n",
    "parser.add_argument('-n', '--network', metavar = 'NETWORK', default = 'network.json',\n",
    "                    help = 'Specify the .json file describing the network trace.')\n",
    "parser.add_argument('-nm', '--network-multiplier', metavar = 'MULTIPLIER',\n",
    "                    type = float, default = 1,\n",
    "                    help = 'Multiply throughput by MULTIPLIER.')\n",
    "parser.add_argument('-m', '--movie', metavar = 'MOVIE', default = 'movie.json',\n",
    "                    help = 'Specify the .json file describing the movie chunks.')\n",
    "parser.add_argument('-ml', '--movie-length', metavar = 'LEN', type = float, default = None,\n",
    "                    help = 'Specify the movie length in seconds (use MOVIE length if None).')\n",
    "parser.add_argument('-a', '--abr', metavar = 'ABR',\n",
    "                    default = sabre.abr_default,\n",
    "                    help = 'Choose ABR algorithm from predefined list (%s), or specify .py module to import.' % ', '.join(sabre.abr_list.keys()))\n",
    "parser.add_argument('-ab', '--abr-basic', action = 'store_true',\n",
    "                    help = 'Set ABR to BASIC (ABR strategy dependant).')\n",
    "parser.add_argument('-ao', '--abr-osc', action = 'store_true',\n",
    "                    help = 'Set ABR to minimize oscillations.')\n",
    "parser.add_argument('-gp', '--gamma-p', metavar = 'GAMMAP', type = float, default = 5,\n",
    "                    help = 'Specify the (gamma p) product in seconds.')\n",
    "parser.add_argument('-noibr', '--no-insufficient-buffer-rule', action = 'store_true',\n",
    "                    help = 'Disable Insufficient Buffer Rule.')\n",
    "parser.add_argument('-ma', '--moving-average', metavar = 'AVERAGE',\n",
    "                    choices = sabre.average_list.keys(), default = sabre.average_default,\n",
    "                    help = 'Specify the moving average strategy (%s).' %\n",
    "                    ', '.join(sabre.average_list.keys()))\n",
    "parser.add_argument('-ws', '--window-size', metavar = 'WINDOW_SIZE',\n",
    "                    nargs = '+', type = int, default = [3],\n",
    "                    help = 'Specify sliding window size.')\n",
    "parser.add_argument('-hl', '--half-life', metavar = 'HALF_LIFE',\n",
    "                    nargs = '+', type = float, default = [3, 8],\n",
    "                    help = 'Specify EWMA half life.')\n",
    "parser.add_argument('-s', '--seek', nargs = 2, metavar = ('WHEN', 'SEEK'),\n",
    "                    type = float, default = None,\n",
    "                    help = 'Specify when to seek in seconds and where to seek in seconds.')\n",
    "choices = ['none', 'left', 'right']\n",
    "parser.add_argument('-r', '--replace', metavar = 'REPLACEMENT',\n",
    "                    #choices = choices,\n",
    "                    default  =  'none',\n",
    "                    help = 'Set replacement strategy from predefined list (%s), or specify .py module to import.' % ', '.join(choices))\n",
    "parser.add_argument('-b', '--max-buffer', metavar = 'MAXBUFFER', type = float, default = 25,\n",
    "                    help = 'Specify the maximum buffer size in seconds.')\n",
    "parser.add_argument('-noa', '--no-abandon', action = 'store_true',\n",
    "                    help = 'Disable abandonment.')\n",
    "parser.add_argument('-rmp', '--rampup-threshold', metavar = 'THRESHOLD',\n",
    "                    type = int, default = None,\n",
    "                    help = 'Specify at what quality index we are ramped up (None matches network).')\n",
    "parser.add_argument('-v', '--verbose', action = 'store_true',\n",
    "                    help = 'Run in verbose mode.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b745e7b2-2c64-4f8c-86d1-32315cd31914",
   "metadata": {},
   "source": [
    "### Gathering the Data\n",
    "Now that the args have been defined to run sabre, the `test_algorithm` function was written to wrap the call. The results are then saved in a data frame for the given traces and movies to test. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2701da74-9867-459f-a057-27ca9bfe3c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_sabre(text):\n",
    "    data = {}\n",
    "    for line in text.splitlines():\n",
    "        line = line.split(':')\n",
    "        assert len(line) == 2\n",
    "        metric, value = line[0], float(line[1].strip())\n",
    "        data[metric] = value\n",
    "    return data\n",
    "\n",
    "def test_algorithm(movies, traces, abr_algo, print_progress=True) -> pd.DataFrame:\n",
    "    if print_progress:\n",
    "        print(f'getting results for: {abr_algo}')\n",
    "\n",
    "    data = []\n",
    "    for m in movies:\n",
    "        for t in traces:\n",
    "            data_row = {'movie':m, 'network_trace':t, 'algorithm':abr_algo}\n",
    "            # parse the args for sabre to run. \n",
    "            # This would normally be done via cli, \n",
    "            # but it is convienient here to do in the notebook\n",
    "            args = parser.parse_args([\n",
    "                '--abr', abr_algo,\n",
    "                '--movie', m,\n",
    "                '--network', t\n",
    "            ])\n",
    "            # capture the results that sabre prints to stdout\n",
    "            with io.StringIO() as buf, contextlib.redirect_stdout(buf):\n",
    "                sabre.main(args)\n",
    "                stdout = buf.getvalue() \n",
    "            # parse the stdout text to a more consumable dict format\n",
    "            results   = parse_sabre(stdout)\n",
    "            data_row.update(results)\n",
    "            data.append(data_row)\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "\n",
    "bola_results    = test_algorithm(movies, DATA['test'], 'bola')\n",
    "dynamic_results = test_algorithm(movies, DATA['test'], 'dynamic')\n",
    "\n",
    "results_df = pd.concat([bola_results, dynamic_results])\n",
    "\n",
    "print('data frame shape: ', results_df.shape)\n",
    "print('columns: ', results_df.columns)\n",
    "\n",
    "results_df.to_csv('../results/results_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc87aaae-1bb0-4351-9818-9e19d6232bd0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": ".env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
