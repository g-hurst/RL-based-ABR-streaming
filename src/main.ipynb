{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea01379e-834e-454d-880f-ad9cb95e1754",
   "metadata": {},
   "source": [
    "# Creating an RL Based ABR Streaming Algorithm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2521427b-e5ec-41c5-b571-90d9eda20348",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import argparse\n",
    "import random\n",
    "import math\n",
    "import io\n",
    "import contextlib\n",
    "\n",
    "import sabre\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66853135-291c-4b49-8b14-69ba6b8a39f0",
   "metadata": {},
   "source": [
    "## Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27df2093-b1db-4a7f-849f-f6fe4e2785c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary of Network Data:\n",
      "  hd_traces: \n",
      "    Training 750 samples, 149250 steps to train\n",
      "    Testing  250 samples, 49750  steps to test\n",
      "\n",
      "  sd_traces: \n",
      "    Training 750 samples, 149250 steps to train\n",
      "    Testing  250 samples, 49750  steps to test\n",
      "\n",
      "  3G_traces: \n",
      "    Training 64 samples, 12736 steps to train\n",
      "    Testing  22 samples, 4378  steps to test\n",
      "\n",
      "  4G_traces: \n",
      "    Training 30 samples, 5970 steps to train\n",
      "    Testing  10 samples, 1990  steps to test\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_files(d): \n",
    "    return [os.path.join(d, f) for f in os.listdir(d)]\n",
    "    \n",
    "def get_movie_manifest(movie_filename):\n",
    "    manifest = sabre.load_json(movie_filename)                                                                                                                                                        \n",
    "    manifest = sabre.ManifestInfo(segment_time = manifest['segment_duration_ms'], \n",
    "                    bitrates    = manifest['bitrates_kbps'],                                         \n",
    "                    utilities    = [math.log(b) - math.log(manifest['bitrates_kbps'][0]) for b in manifest['bitrates_kbps']], \n",
    "                    segments     = manifest['segment_sizes_bits'])\n",
    "    return manifest\n",
    "    \n",
    "network_hd_dir = '../data/hd_fs'\n",
    "network_sd_dir = '../data/sd_fs'\n",
    "network_3G_dir = '../data/3Glogs'\n",
    "network_4G_dir = '../data/4Glogs'\n",
    "\n",
    "network_traces = {\n",
    "    'hd_traces':get_files(network_hd_dir),\n",
    "    'sd_traces':get_files(network_sd_dir),\n",
    "    '3G_traces':get_files(network_3G_dir),\n",
    "    '4G_traces':get_files(network_4G_dir),\n",
    "}\n",
    "\n",
    "movies = ['../data/bbb.json',] #  '../data/bbb4k.json']\n",
    "\n",
    "# for now seed the random in order to save the trained model one day\n",
    "# and then re-run the code to test another day\n",
    "random.seed(69420) \n",
    "\n",
    "n_views_per_trace = 1\n",
    "n_chunks = sum(len(get_movie_manifest(m).segments) for m in movies)\n",
    "print('Summary of Network Data:')\n",
    "test_train_split = 0.75\n",
    "for k, v in network_traces.items():\n",
    "    np.random.shuffle(v)\n",
    "    idx = int(np.floor(test_train_split * len(v)))\n",
    "    n_train = n_views_per_trace * n_chunks * idx\n",
    "    n_test  = n_chunks * (len(v) - idx)\n",
    "    network_traces[k] = {\n",
    "        'train': v[:idx],\n",
    "        'train_steps': n_train,\n",
    "        'test':  v[idx:],\n",
    "        'test_steps': n_test\n",
    "    }\n",
    "    print(f'  {k}: ')\n",
    "    print(f'    Training {idx} samples, {n_train} steps to train')\n",
    "    print(f'    Testing  {len(v) - idx} samples, {n_test}  steps to test')\n",
    "    print('')\n",
    "\n",
    "DATA = network_traces['hd_traces']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a53af16-6872-4747-99e1-bafc07da1a20",
   "metadata": {},
   "source": [
    "## Train and save several models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28e03ff9-acb6-451a-a4cd-748cb0c16e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from environment import ABR_Env\n",
    "\n",
    "qoe_alpha, qoe_beta, qoe_delta = (1, 1, 1)\n",
    "\n",
    "env = ABR_Env(\n",
    "    DATA['train'],\n",
    "    movies,\n",
    "    r_multipliers=[qoe_alpha, qoe_beta, qoe_delta],\n",
    ")\n",
    "env_train = env.get_sb_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9baa29d0-0131-471f-a0e6-c369dce0df2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 175      |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 2        |\n",
      "|    total_timesteps    | 500      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.4     |\n",
      "|    explained_variance | 0.0566   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | 5.07     |\n",
      "|    value_loss         | 114      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 174      |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 5        |\n",
      "|    total_timesteps    | 1000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -1.37    |\n",
      "|    explained_variance | 0.357    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 199      |\n",
      "|    policy_loss        | 1.53     |\n",
      "|    value_loss         | 106      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| time/                 |          |\n",
      "|    fps                | 179      |\n",
      "|    iterations         | 300      |\n",
      "|    time_elapsed       | 8        |\n",
      "|    total_timesteps    | 1500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.608   |\n",
      "|    explained_variance | -0.00695 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 299      |\n",
      "|    policy_loss        | 13.5     |\n",
      "|    value_loss         | 336      |\n",
      "------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mstable_baselines3\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m A2C\n\u001b[1;32m      3\u001b[0m model_a2c \u001b[38;5;241m=\u001b[39m A2C(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMultiInputPolicy\u001b[39m\u001b[38;5;124m'\u001b[39m, env_train, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m \u001b[43mmodel_a2c\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDATA\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain_steps\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m model_a2c\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../models/a2c.model\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/school/ECE595-RL/RL-based-ABR-streaming/.env/lib/python3.10/site-packages/stable_baselines3/a2c/a2c.py:201\u001b[0m, in \u001b[0;36mA2C.learn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlearn\u001b[39m(\n\u001b[1;32m    193\u001b[0m     \u001b[38;5;28mself\u001b[39m: SelfA2C,\n\u001b[1;32m    194\u001b[0m     total_timesteps: \u001b[38;5;28mint\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    199\u001b[0m     progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    200\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SelfA2C:\n\u001b[0;32m--> 201\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    203\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    205\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtb_log_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    206\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    207\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    208\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/school/ECE595-RL/RL-based-ABR-streaming/.env/lib/python3.10/site-packages/stable_baselines3/common/on_policy_algorithm.py:336\u001b[0m, in \u001b[0;36mOnPolicyAlgorithm.learn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mep_info_buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    334\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dump_logs(iteration)\n\u001b[0;32m--> 336\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    338\u001b[0m callback\u001b[38;5;241m.\u001b[39mon_training_end()\n\u001b[1;32m    340\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/Documents/school/ECE595-RL/RL-based-ABR-streaming/.env/lib/python3.10/site-packages/stable_baselines3/a2c/a2c.py:175\u001b[0m, in \u001b[0;36mA2C.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;66;03m# Optimization step\u001b[39;00m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpolicy\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m--> 175\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;66;03m# Clip grad norm\u001b[39;00m\n\u001b[1;32m    178\u001b[0m th\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpolicy\u001b[38;5;241m.\u001b[39mparameters(), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_grad_norm)\n",
      "File \u001b[0;32m~/Documents/school/ECE595-RL/RL-based-ABR-streaming/.env/lib/python3.10/site-packages/torch/_tensor.py:581\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    572\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    573\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    574\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    579\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    580\u001b[0m     )\n\u001b[0;32m--> 581\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    582\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    583\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/school/ECE595-RL/RL-based-ABR-streaming/.env/lib/python3.10/site-packages/torch/autograd/__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/school/ECE595-RL/RL-based-ABR-streaming/.env/lib/python3.10/site-packages/torch/autograd/graph.py:825\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    828\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    829\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from stable_baselines3 import A2C\n",
    "\n",
    "model_a2c = A2C('MultiInputPolicy', env_train, verbose=1, device='cpu')\n",
    "model_a2c.learn(total_timesteps=DATA['train_steps'])\n",
    "model_a2c.save('../models/a2c.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de9a7f3f-1c88-4996-8276-40b4dacf68a0",
   "metadata": {},
   "source": [
    "## Test the ABR Algorithms and Gather Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8aab492-9a3a-4028-8c02-e57c8dc0dbfe",
   "metadata": {},
   "source": [
    "The argparse arguments were copied and pased from the modified `sabre.py` file. Note, minor changes were made where any variable that was used had to be changed to sabre.var_name. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "733c4fff-ba58-4803-87b8-06322ac22a98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreTrueAction(option_strings=['-v', '--verbose'], dest='verbose', nargs=0, const=True, default=False, type=None, choices=None, required=False, help='Run in verbose mode.', metavar=None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser(description = 'Simulate an ABR session.',\n",
    "                                 formatter_class = argparse.ArgumentDefaultsHelpFormatter)\n",
    "parser.add_argument('-n', '--network', metavar = 'NETWORK', default = 'network.json',\n",
    "                    help = 'Specify the .json file describing the network trace.')\n",
    "parser.add_argument('-nm', '--network-multiplier', metavar = 'MULTIPLIER',\n",
    "                    type = float, default = 1,\n",
    "                    help = 'Multiply throughput by MULTIPLIER.')\n",
    "parser.add_argument('-m', '--movie', metavar = 'MOVIE', default = 'movie.json',\n",
    "                    help = 'Specify the .json file describing the movie chunks.')\n",
    "parser.add_argument('-ml', '--movie-length', metavar = 'LEN', type = float, default = None,\n",
    "                    help = 'Specify the movie length in seconds (use MOVIE length if None).')\n",
    "parser.add_argument('-a', '--abr', metavar = 'ABR',\n",
    "                    default = sabre.abr_default,\n",
    "                    help = 'Choose ABR algorithm from predefined list (%s), or specify .py module to import.' % ', '.join(sabre.abr_list.keys()))\n",
    "parser.add_argument('-ab', '--abr-basic', action = 'store_true',\n",
    "                    help = 'Set ABR to BASIC (ABR strategy dependant).')\n",
    "parser.add_argument('-ao', '--abr-osc', action = 'store_true',\n",
    "                    help = 'Set ABR to minimize oscillations.')\n",
    "parser.add_argument('-gp', '--gamma-p', metavar = 'GAMMAP', type = float, default = 5,\n",
    "                    help = 'Specify the (gamma p) product in seconds.')\n",
    "parser.add_argument('-noibr', '--no-insufficient-buffer-rule', action = 'store_true',\n",
    "                    help = 'Disable Insufficient Buffer Rule.')\n",
    "parser.add_argument('-ma', '--moving-average', metavar = 'AVERAGE',\n",
    "                    choices = sabre.average_list.keys(), default = sabre.average_default,\n",
    "                    help = 'Specify the moving average strategy (%s).' %\n",
    "                    ', '.join(sabre.average_list.keys()))\n",
    "parser.add_argument('-ws', '--window-size', metavar = 'WINDOW_SIZE',\n",
    "                    nargs = '+', type = int, default = [3],\n",
    "                    help = 'Specify sliding window size.')\n",
    "parser.add_argument('-hl', '--half-life', metavar = 'HALF_LIFE',\n",
    "                    nargs = '+', type = float, default = [3, 8],\n",
    "                    help = 'Specify EWMA half life.')\n",
    "parser.add_argument('-s', '--seek', nargs = 2, metavar = ('WHEN', 'SEEK'),\n",
    "                    type = float, default = None,\n",
    "                    help = 'Specify when to seek in seconds and where to seek in seconds.')\n",
    "choices = ['none', 'left', 'right']\n",
    "parser.add_argument('-r', '--replace', metavar = 'REPLACEMENT',\n",
    "                    #choices = choices,\n",
    "                    default  =  'none',\n",
    "                    help = 'Set replacement strategy from predefined list (%s), or specify .py module to import.' % ', '.join(choices))\n",
    "parser.add_argument('-b', '--max-buffer', metavar = 'MAXBUFFER', type = float, default = 25,\n",
    "                    help = 'Specify the maximum buffer size in seconds.')\n",
    "parser.add_argument('-noa', '--no-abandon', action = 'store_true',\n",
    "                    help = 'Disable abandonment.')\n",
    "parser.add_argument('-rmp', '--rampup-threshold', metavar = 'THRESHOLD',\n",
    "                    type = int, default = None,\n",
    "                    help = 'Specify at what quality index we are ramped up (None matches network).')\n",
    "parser.add_argument('-v', '--verbose', action = 'store_true',\n",
    "                    help = 'Run in verbose mode.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b745e7b2-2c64-4f8c-86d1-32315cd31914",
   "metadata": {},
   "source": [
    "### Gathering the Data\n",
    "Now that the args have been defined to run sabre, the `test_algorithm` function was written to wrap the call. The results are then saved in a data frame for the given traces and movies to test. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2701da74-9867-459f-a057-27ca9bfe3c4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting results for: bola\n",
      "getting results for: dynamic\n",
      "data frame shape:  (500, 27)\n",
      "columns:  Index(['movie', 'network_trace', 'algorithm', 'buffer size',\n",
      "       'total played utility', 'time average played utility',\n",
      "       'total played bitrate', 'time average played bitrate',\n",
      "       'total play time', 'total play time chunks', 'total rebuffer',\n",
      "       'rebuffer ratio', 'time average rebuffer', 'total rebuffer events',\n",
      "       'time average rebuffer events', 'total bitrate change',\n",
      "       'time average bitrate change', 'total log bitrate change',\n",
      "       'time average log bitrate change', 'time average score',\n",
      "       'over estimate count', 'over estimate', 'leq estimate count',\n",
      "       'leq estimate', 'estimate', 'rampup time', 'total reaction time'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "def parse_sabre(text):\n",
    "    data = {}\n",
    "    for line in text.splitlines():\n",
    "        line = line.split(':')\n",
    "        assert len(line) == 2\n",
    "        metric, value = line[0], float(line[1].strip())\n",
    "        data[metric] = value\n",
    "    return data\n",
    "\n",
    "def test_algorithm(movies, traces, abr_algo, print_progress=True) -> pd.DataFrame:\n",
    "    if print_progress:\n",
    "        print(f'getting results for: {abr_algo}')\n",
    "\n",
    "    data = []\n",
    "    for m in movies:\n",
    "        for t in traces:\n",
    "            data_row = {'movie':m, 'network_trace':t, 'algorithm':abr_algo}\n",
    "            # parse the args for sabre to run. \n",
    "            # This would normally be done via cli, \n",
    "            # but it is convienient here to do in the notebook\n",
    "            args = parser.parse_args([\n",
    "                '--abr', abr_algo,\n",
    "                '--movie', m,\n",
    "                '--network', t\n",
    "            ])\n",
    "            # capture the results that sabre prints to stdout\n",
    "            with io.StringIO() as buf, contextlib.redirect_stdout(buf):\n",
    "                sabre.main(args)\n",
    "                stdout = buf.getvalue() \n",
    "            # parse the stdout text to a more consumable dict format\n",
    "            results   = parse_sabre(stdout)\n",
    "            data_row.update(results)\n",
    "            data.append(data_row)\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "\n",
    "bola_results    = test_algorithm(movies, DATA['test'], 'bola')\n",
    "dynamic_results = test_algorithm(movies, DATA['test'], 'dynamic')\n",
    "\n",
    "results_df = pd.concat([bola_results, dynamic_results])\n",
    "\n",
    "print('data frame shape: ', results_df.shape)\n",
    "print('columns: ', results_df.columns)\n",
    "\n",
    "results_df.to_csv('../results/results_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc87aaae-1bb0-4351-9818-9e19d6232bd0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": ".env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
